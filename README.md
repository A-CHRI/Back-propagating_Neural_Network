# Back-propagating_Neural_Network
Exam project in the course "Introduction to Intelligent Systems"

Comparison between a Long Short-Term Memory Recurrent Neural Network (LSTM-RNN), and a Linear ReLU stack Conventional Neural Network (CNN), on it's ability to predict various stock-features based on previous data from other stocks.

## Models
### LSTM RNN
 - LSTM layer
   - Hidden cells: 70
   - Hidden layers: 2
   - Dropout: 0.2
 - Linear layer

### CNN 
- Linear layer
- ReLU layer
- Linear layer
- ReLU layer
- Linear layer
